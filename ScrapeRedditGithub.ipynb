{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42bca5d2",
   "metadata": {},
   "source": [
    "# Reddit scraping\n",
    "\n",
    "Based on the instructions given at https://github.com/pushshift/api and https://praw.readthedocs.io/en/latest/getting_started/authentication.html\n",
    "\n",
    "for personal use only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['https://www.reddit.com/r/...', \n",
    "        'https://www.reddit.com/r/...',\n",
    "        'https://www.reddit.com/r/...',\n",
    "        'https://www.reddit.com/r/...']\n",
    "\n",
    "subreddit_names = [ele.split('/')[-1] for ele in subreddits]\n",
    "\n",
    "url_api = 'https://api.pushshift.io/reddit'\n",
    "\n",
    "comment_id_ep = 'submission/comment_ids'\n",
    "submisison_ep = 'search/submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get submissions\n",
    "\n",
    "def get_submissions(subreddit_name):\n",
    "    \n",
    "    # period in days\n",
    "    period = 120\n",
    "    n_max = 50\n",
    "\n",
    "    n = 1000\n",
    "    \n",
    "    submissions = []\n",
    "    bool_none = False\n",
    "    \n",
    "    for i in range(n_max):\n",
    "        print(f'[{i+1}/{n_max}]: minus {(i+1)*period} days to {i*period}')\n",
    "        url_request = f'{url_api}/{submisison_ep}/?subreddit={subreddit_name}&sort_type=created_utc&size={n}&after={(i+1)*period}d&before={i*period}d'\n",
    "\n",
    "        response = requests.get(url_request)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print('Success!')\n",
    "        elif response.status_code == 404:\n",
    "            print('Not Found.')\n",
    "            continue\n",
    "\n",
    "        json_data = json.loads(response.text)\n",
    "\n",
    "        if not('data' in json_data.keys()):\n",
    "            print('No data found')\n",
    "            continue\n",
    "\n",
    "        n_submissions = len(json_data['data'])\n",
    "\n",
    "        if (n_submissions <= 0):\n",
    "            print('No submissions found')\n",
    "            if (bool_none):\n",
    "                break\n",
    "            \n",
    "            bool_none = True\n",
    "            continue\n",
    "\n",
    "        submissions.extend(json_data['data'])\n",
    "        \n",
    "    return submissions\n",
    "\n",
    "\n",
    "def get_reddit():\n",
    "    \n",
    "    # See https://praw.readthedocs.io/en/latest/getting_started/authentication.html\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"\",\n",
    "        client_secret=\"\",\n",
    "        password=\"\",\n",
    "        user_agent=\"\",\n",
    "        username=\"\",\n",
    "    )\n",
    "    \n",
    "    return reddit\n",
    "\n",
    "def export_subreddit(subreddit_name, submission_ids, path_base):\n",
    "\n",
    "    reddit = get_reddit()\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    dt_unix = dt.datetime(1970, 1, 1)\n",
    "\n",
    "    path_subreddit_out = os.path.join(path_base, subreddit_name)\n",
    "\n",
    "    if not(os.path.isdir(path_subreddit_out)):\n",
    "        os.mkdir(path_subreddit_out)\n",
    "\n",
    "    print(subreddit.display_name)\n",
    "\n",
    "    S = {}\n",
    "\n",
    "    submissions_text, submissions_up, submissions_down, submissions_created = [], [], [], []\n",
    "\n",
    "    for i, submission_id in enumerate(submission_ids):\n",
    "        print(f'Submission [{i+1}/{len(submission_ids)}]')\n",
    "\n",
    "        # Get\n",
    "        submission = reddit.submission(submission_id)\n",
    "\n",
    "        # Set\n",
    "        submission_title = submissions.title\n",
    "        submission_text = submission.selftext\n",
    "        submission_up = submission.ups\n",
    "        submission_down = submission.downs\n",
    "        submission_created = dt_unix + dt.timedelta(seconds=submission.created_utc)\n",
    "\n",
    "        # Convert\n",
    "        submission_created = submission_created.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "        # Append\n",
    "        submissions_title.append(submission_title)\n",
    "        submissions_text.append(submission_text)\n",
    "        submissions_up.append(submission_up)\n",
    "        submissions_down.append(submission_down)\n",
    "        submissions_created.append(submission_created)\n",
    "\n",
    "        # Define\n",
    "        path_submission_out = os.path.join(path_subreddit_out, 'submissions')\n",
    "\n",
    "        if not(os.path.isdir(path_submission_out)):\n",
    "            os.mkdir(path_submission_out)\n",
    "\n",
    "        # Initialize\n",
    "        SC = {}\n",
    "\n",
    "        comments_text, comments_up, comments_down, comments_created = [], [], [], []\n",
    "\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        comments = submission.comments.list()\n",
    "        n_comments = len(comments)\n",
    "        for j, comment in enumerate(comments):\n",
    "            print(f'\\tComment [{j+1}/{n_comments}]')\n",
    "\n",
    "            # Set\n",
    "            comment_text = comment.body\n",
    "            comment_up = comment.ups\n",
    "            comment_down = comment.downs\n",
    "            comment_created = dt_unix + dt.timedelta(seconds=comment.created_utc)\n",
    "\n",
    "            if ('[deleted]' in comment_text):\n",
    "                continue\n",
    "\n",
    "            # Convert\n",
    "            comment_created = comment_created.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "            # Append\n",
    "            comments_text.append(comment_text)\n",
    "            comments_up.append(comment_up)\n",
    "            comments_down.append(comment_down)\n",
    "            comments_created.append(comment_created)\n",
    "\n",
    "        # Add\n",
    "        SC['text'] = [f'{submission_title} QQQ {submission_text}'] + comments_text\n",
    "        SC['up'] = [submission_up] + comments_up\n",
    "        SC['down'] = [submission_down] + comments_down\n",
    "        SC['created'] = [submission_created] + comments_created\n",
    "\n",
    "        # Create\n",
    "        df = pd.DataFrame(SC)\n",
    "\n",
    "        # Set\n",
    "        filename_csv = f'{subreddit_name}_{submission_id}_{submission_created}.csv'\n",
    "        file_csv = os.path.join(path_submission_out, filename_csv)\n",
    "\n",
    "        # Export\n",
    "        df.to_csv(file_csv, sep='\\t', index=False)\n",
    "\n",
    "    # Add\n",
    "    S['title'] = submissions_title\n",
    "    S['text'] = submissions_text\n",
    "    S['up'] = submissions_up\n",
    "    S['down'] = submissions_down\n",
    "    S['created'] = submissions_created\n",
    "\n",
    "    # Create\n",
    "    df = pd.DataFrame(S)\n",
    "\n",
    "    # Set\n",
    "    filename_csv = f'{subreddit_name}_{n_submissions}.csv'\n",
    "    file_csv = os.path.join(path_subreddit_out, filename_csv)\n",
    "\n",
    "    # Export\n",
    "    df.to_csv(file_csv, sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4f7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_base = r'C:\\path\\to\\output'\n",
    "\n",
    "# Iterate over subreddits\n",
    "for k, subreddit_name in enumerate(subreddit_names):\n",
    "    print(f'[{k+1}/{len(subreddit_names)}]: {subreddit_name}')\n",
    "\n",
    "    # Get submissions\n",
    "    submissions = get_submissions(subreddit_name)\n",
    "\n",
    "    # Get submission ids\n",
    "    submission_ids = [ele['id'] for ele in submissions]\n",
    "\n",
    "    # Export\n",
    "    export_subreddit(subreddit_name, submission_ids, path_base)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
